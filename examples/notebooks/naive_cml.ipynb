{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PytorchCML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../../src/\")\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from PytorchCML import losses, models, samplers, evaluators, trainers\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = pd.read_csv(\n",
    "  'http://files.grouplens.org/datasets/movielens/ml-100k/u.data', \n",
    "  sep='\\t', header=None, index_col=None,\n",
    ")\n",
    "movielens.columns = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "movielens.user_id -= 1\n",
    "movielens.item_id -= 1\n",
    "movielens.rating = (movielens >= 4).astype(int)\n",
    "n_user = movielens.user_id.nunique()\n",
    "n_item = movielens.item_id.nunique()\n",
    "\n",
    "train, test = train_test_split(movielens)\n",
    "\n",
    "\n",
    "# all user item pairs\n",
    "df_all = pd.DataFrame(\n",
    "    [[u, i] for u,i in product(range(n_user), range(n_item))],\n",
    "    columns=[\"user_id\", \"item_id\"]\n",
    ")\n",
    "\n",
    "# frag train pairs\n",
    "df_all = pd.merge(\n",
    "    df_all, \n",
    "    train[[\"user_id\", \"item_id\", \"rating\"]], \n",
    "    on=[\"user_id\", \"item_id\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# remove train pairs\n",
    "test = pd.merge(\n",
    "    df_all[df_all.rating.isna()][[\"user_id\", \"item_id\"]], \n",
    "    test[[\"user_id\", \"item_id\", \"rating\"]], \n",
    "    on=[\"user_id\", \"item_id\"], \n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# numpy array\n",
    "train_set = train[train.rating == 1][[\"user_id\", \"item_id\"]].values\n",
    "test_set = test[[\"user_id\", \"item_id\", \"rating\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 1e-3\n",
    "n_dim = 10\n",
    "model = models.CollaborativeMetricLearning(n_user, n_item, n_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = losses.SumTripletLoss(margin=1).to(device)\n",
    "sampler = samplers.BaseSampler(train_set, device=device)\n",
    "\n",
    "score_function_dict = {\n",
    "    \"nDCG\" : evaluators.ndcg,\n",
    "    \"MAP\" : evaluators.average_precision,\n",
    "    \"Recall\": evaluators.recall\n",
    "}\n",
    "evaluator = evaluators.UserwiseEvaluator(torch.LongTensor(test_set).to(device), score_function_dict, ks=[3,5])\n",
    "trainer = trainers.CMLTrainer(model, optimizer, criterion, sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 943/943 [00:29<00:00, 31.69it/s]\n",
      "epoch1 avg_loss:2455.606: 100%|██████████| 256/256 [00:09<00:00, 27.55it/s]\n",
      "epoch2 avg_loss:2122.508: 100%|██████████| 256/256 [00:09<00:00, 27.80it/s]\n",
      "epoch3 avg_loss:1900.206: 100%|██████████| 256/256 [00:09<00:00, 27.71it/s]\n",
      "epoch4 avg_loss:1762.980: 100%|██████████| 256/256 [00:12<00:00, 20.54it/s]\n",
      "epoch5 avg_loss:1672.857: 100%|██████████| 256/256 [00:10<00:00, 24.40it/s]\n",
      "epoch6 avg_loss:1601.967: 100%|██████████| 256/256 [00:09<00:00, 26.00it/s]\n",
      "epoch7 avg_loss:1539.010: 100%|██████████| 256/256 [00:10<00:00, 24.79it/s]\n",
      "epoch8 avg_loss:1490.909: 100%|██████████| 256/256 [00:10<00:00, 25.41it/s]\n",
      "epoch9 avg_loss:1448.377: 100%|██████████| 256/256 [00:10<00:00, 24.69it/s]\n",
      "epoch10 avg_loss:1405.806: 100%|██████████| 256/256 [00:09<00:00, 25.88it/s]\n",
      "100%|██████████| 943/943 [00:32<00:00, 29.25it/s]\n",
      "epoch11 avg_loss:1357.743: 100%|██████████| 256/256 [00:08<00:00, 28.93it/s]\n",
      "epoch12 avg_loss:1301.213: 100%|██████████| 256/256 [00:11<00:00, 21.40it/s]\n",
      "epoch13 avg_loss:1262.669: 100%|██████████| 256/256 [00:09<00:00, 26.02it/s]\n",
      "epoch14 avg_loss:1202.404: 100%|██████████| 256/256 [00:10<00:00, 24.92it/s]\n",
      "epoch15 avg_loss:1164.722: 100%|██████████| 256/256 [00:10<00:00, 24.70it/s]\n",
      "epoch16 avg_loss:1123.845: 100%|██████████| 256/256 [00:10<00:00, 24.68it/s]\n",
      "epoch17 avg_loss:1075.751: 100%|██████████| 256/256 [00:10<00:00, 25.51it/s]\n",
      "epoch18 avg_loss:1034.589: 100%|██████████| 256/256 [00:11<00:00, 22.99it/s]\n",
      "epoch19 avg_loss:996.019: 100%|██████████| 256/256 [00:10<00:00, 25.35it/s]\n",
      "epoch20 avg_loss:973.621: 100%|██████████| 256/256 [00:10<00:00, 24.49it/s]\n",
      "100%|██████████| 943/943 [00:37<00:00, 24.90it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=256, n_epoch=20, valid_evaluator = evaluator, valid_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nDCG@3     MAP@3  Recall@3    nDCG@5     MAP@5  Recall@5  epoch  \\\n",
       "0  0.014991  0.021031  0.001748  0.015392  0.021031  0.002650      0   \n",
       "0  0.032581  0.050266  0.002588  0.034547  0.050266  0.004647     10   \n",
       "0  0.114106  0.093020  0.013257  0.114185  0.093020  0.022119     20   \n",
       "\n",
       "          loss  \n",
       "0          NaN  \n",
       "0  1405.806201  \n",
       "0   973.621241  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nDCG@3</th>\n      <th>MAP@3</th>\n      <th>Recall@3</th>\n      <th>nDCG@5</th>\n      <th>MAP@5</th>\n      <th>Recall@5</th>\n      <th>epoch</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.014991</td>\n      <td>0.021031</td>\n      <td>0.001748</td>\n      <td>0.015392</td>\n      <td>0.021031</td>\n      <td>0.002650</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.032581</td>\n      <td>0.050266</td>\n      <td>0.002588</td>\n      <td>0.034547</td>\n      <td>0.050266</td>\n      <td>0.004647</td>\n      <td>10</td>\n      <td>1405.806201</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.114106</td>\n      <td>0.093020</td>\n      <td>0.013257</td>\n      <td>0.114185</td>\n      <td>0.093020</td>\n      <td>0.022119</td>\n      <td>20</td>\n      <td>973.621241</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}