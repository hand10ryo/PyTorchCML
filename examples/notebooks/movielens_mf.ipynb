{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PytorchCML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src/\")\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from PytorchCML import losses, models, samplers, evaluators, trainers\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_init(X, dim):\n",
    "    \"\"\"\n",
    "    Args :\n",
    "        X : csr_matrix which element is 0 or 1.\n",
    "        dim : number of dimention\n",
    "    \"\"\"\n",
    "    svd = TruncatedSVD(n_components=10)\n",
    "    U_ = svd.fit_transform(X)\n",
    "    V_ = svd.components_\n",
    "\n",
    "    s = (U_.sum(axis=1).mean() + V_.sum(axis=0).mean()) / 2\n",
    "    U = 2 ** 0.5 * U_ - (1 / n_dim) ** 0.5 * s * np.ones_like(U_)\n",
    "    V = 2 ** 0.5 * V_ + (1 / n_dim) ** 0.5 / s * np.ones_like(V_)\n",
    "    ub = -(2 / n_dim) ** 0.5 * U_.sum(axis=1) / s\n",
    "    vb = (2 / n_dim) ** 0.5 * V_.sum(axis=0) * s\n",
    "\n",
    "    return U, V, ub, vb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = pd.read_csv(\n",
    "  'http://files.grouplens.org/datasets/movielens/ml-100k/u.data', \n",
    "  sep='\\t', header=None, index_col=None,\n",
    ")\n",
    "movielens.columns = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "movielens.user_id -= 1\n",
    "movielens.item_id -= 1\n",
    "movielens.rating = (movielens.rating >= 4).astype(int)\n",
    "n_user = movielens.user_id.nunique()\n",
    "n_item = movielens.item_id.nunique()\n",
    "\n",
    "train, test = train_test_split(movielens.copy())\n",
    "\n",
    "\n",
    "# all user item pairs\n",
    "df_all = pd.DataFrame(\n",
    "    [[u, i] for u,i in product(range(n_user), range(n_item))],\n",
    "    columns=[\"user_id\", \"item_id\"]\n",
    ")\n",
    "\n",
    "# frag train pairs\n",
    "df_all = pd.merge(\n",
    "    df_all, \n",
    "    train[[\"user_id\", \"item_id\", \"rating\"]], \n",
    "    on=[\"user_id\", \"item_id\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# remove train pairs\n",
    "test = pd.merge(\n",
    "    df_all[df_all.rating.isna()][[\"user_id\", \"item_id\"]], \n",
    "    test[[\"user_id\", \"item_id\", \"rating\"]], \n",
    "    on=[\"user_id\", \"item_id\"], \n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# numpy array\n",
    "train_set = train[train.rating == 1][[\"user_id\", \"item_id\"]].values\n",
    "test_set = test[[\"user_id\", \"item_id\", \"rating\"]].values\n",
    "\n",
    "# to torch.Tensor\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_set = torch.LongTensor(train_set).to(device)\n",
    "test_set = torch.LongTensor(test_set).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 10\n",
    "X = csr_matrix(\n",
    "    (np.ones(train_set.shape[0]), (train_set[:,0], train_set[:,1])),\n",
    "    shape=[n_user, n_item]\n",
    ")\n",
    "U, V, ub, vb = svd_init(X, n_dim)"
   ]
  },
  {
   "source": [
    "# Naive MF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 1e-3\n",
    "n_dim = 10\n",
    "model = models.LogitMatrixFactorization(\n",
    "    n_user, n_item, n_dim, max_norm=5,max_bias=3,\n",
    "    user_embedding_init = torch.Tensor(U), \n",
    "    item_embedding_init = torch.Tensor(V.T),\n",
    "    user_bias_init = torch.Tensor(ub), \n",
    "    item_bias_init = torch.Tensor(vb)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = losses.LogitPairwiseLoss().to(device)\n",
    "sampler = samplers.BaseSampler(train_set, n_user, n_item, device=device,n_neg_samples=5, batch_size=1024)\n",
    "\n",
    "score_function_dict = {\n",
    "    \"nDCG\" : evaluators.ndcg,\n",
    "    \"MAP\" : evaluators.average_precision,\n",
    "    \"Recall\": evaluators.recall\n",
    "}\n",
    "evaluator = evaluators.UserwiseEvaluator(torch.LongTensor(test_set).to(device), score_function_dict, ks=[3])\n",
    "trainer = trainers.MFTrainer(model, optimizer, criterion, sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 943/943 [00:15<00:00, 59.02it/s]\n",
      "epoch1 avg_loss:0.483: 100%|██████████| 50/50 [00:01<00:00, 29.97it/s]\n",
      "epoch2 avg_loss:0.432: 100%|██████████| 50/50 [00:01<00:00, 28.96it/s]\n",
      "epoch3 avg_loss:0.397: 100%|██████████| 50/50 [00:01<00:00, 27.35it/s]\n",
      "epoch4 avg_loss:0.374: 100%|██████████| 50/50 [00:01<00:00, 29.84it/s]\n",
      "epoch5 avg_loss:0.356: 100%|██████████| 50/50 [00:01<00:00, 27.78it/s]\n",
      "100%|██████████| 943/943 [00:16<00:00, 56.00it/s]\n",
      "epoch6 avg_loss:0.342: 100%|██████████| 50/50 [00:01<00:00, 30.99it/s]\n",
      "epoch7 avg_loss:0.333: 100%|██████████| 50/50 [00:01<00:00, 25.26it/s]\n",
      "epoch8 avg_loss:0.323: 100%|██████████| 50/50 [00:02<00:00, 22.10it/s]\n",
      "epoch9 avg_loss:0.316: 100%|██████████| 50/50 [00:04<00:00, 10.34it/s]\n",
      "epoch10 avg_loss:0.309: 100%|██████████| 50/50 [00:02<00:00, 17.51it/s]\n",
      "100%|██████████| 943/943 [00:18<00:00, 50.22it/s]\n",
      "epoch11 avg_loss:0.305: 100%|██████████| 50/50 [00:01<00:00, 26.74it/s]\n",
      "epoch12 avg_loss:0.300: 100%|██████████| 50/50 [00:02<00:00, 23.22it/s]\n",
      "epoch13 avg_loss:0.296: 100%|██████████| 50/50 [00:02<00:00, 23.00it/s]\n",
      "epoch14 avg_loss:0.293: 100%|██████████| 50/50 [00:02<00:00, 19.72it/s]\n",
      "epoch15 avg_loss:0.290: 100%|██████████| 50/50 [00:02<00:00, 22.30it/s]\n",
      "100%|██████████| 943/943 [00:20<00:00, 46.42it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=50, n_epoch=15, valid_evaluator = evaluator, valid_per_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nDCG@3     MAP@3  Recall@3  epoch      loss\n",
       "0  0.404477  0.545157  0.111933      0       NaN\n",
       "0  0.408631  0.549399  0.115896      5  0.356066\n",
       "0  0.399501  0.540827  0.115340     10  0.308907\n",
       "0  0.395533  0.534553  0.116172     15  0.289745"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nDCG@3</th>\n      <th>MAP@3</th>\n      <th>Recall@3</th>\n      <th>epoch</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.404477</td>\n      <td>0.545157</td>\n      <td>0.111933</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.408631</td>\n      <td>0.549399</td>\n      <td>0.115896</td>\n      <td>5</td>\n      <td>0.356066</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.399501</td>\n      <td>0.540827</td>\n      <td>0.115340</td>\n      <td>10</td>\n      <td>0.308907</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.395533</td>\n      <td>0.534553</td>\n      <td>0.116172</td>\n      <td>15</td>\n      <td>0.289745</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "source": [
    "# RelMF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"popularity\"] = train.groupby(\"item_id\").rating.transform(sum)\n",
    "train[\"pscore\"] = 1 / (train.popularity / train.popularity.max()) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 1e-3\n",
    "n_dim = 10\n",
    "\n",
    "train_set = train[train.rating == 1][[\"user_id\", \"item_id\", \"pscore\"]].values\n",
    "train_set = torch.LongTensor(train_set).to(device)\n",
    "\n",
    "model = models.LogitMatrixFactorization(\n",
    "    n_user, n_item, n_dim, max_norm=5,max_bias=3,\n",
    "    user_embedding_init = torch.Tensor(U), \n",
    "    item_embedding_init = torch.Tensor(V.T),\n",
    "    user_bias_init = torch.Tensor(ub), \n",
    "    item_bias_init = torch.Tensor(vb)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = losses.RelevancePairwiseLoss(delta=\"rmse\").to(device)\n",
    "sampler = samplers.BaseSampler(train_set, n_user, n_item, device=device,n_neg_samples=5, batch_size=1024)\n",
    "\n",
    "score_function_dict = {\n",
    "    \"nDCG\" : evaluators.ndcg,\n",
    "    \"MAP\" : evaluators.average_precision,\n",
    "    \"Recall\": evaluators.recall\n",
    "}\n",
    "evaluator = evaluators.UserwiseEvaluator(torch.LongTensor(test_set).to(device), score_function_dict, ks=[3])\n",
    "trainer = trainers.MFTrainer(\n",
    "    model, optimizer, criterion, sampler, \n",
    "    column_names={\"user_id\":0, \"item_id\":1, \"pscore\":2}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 943/943 [00:15<00:00, 60.70it/s]\n",
      "epoch1 avg_loss:0.873: 100%|██████████| 50/50 [00:02<00:00, 17.79it/s]\n",
      "epoch2 avg_loss:0.575: 100%|██████████| 50/50 [00:01<00:00, 26.68it/s]\n",
      "epoch3 avg_loss:0.441: 100%|██████████| 50/50 [00:01<00:00, 28.20it/s]\n",
      "epoch4 avg_loss:0.358: 100%|██████████| 50/50 [00:01<00:00, 26.18it/s]\n",
      "epoch5 avg_loss:0.308: 100%|██████████| 50/50 [00:01<00:00, 26.51it/s]\n",
      "100%|██████████| 943/943 [00:19<00:00, 49.52it/s]\n",
      "epoch6 avg_loss:0.267: 100%|██████████| 50/50 [00:01<00:00, 27.11it/s]\n",
      "epoch7 avg_loss:0.240: 100%|██████████| 50/50 [00:01<00:00, 30.29it/s]\n",
      "epoch8 avg_loss:0.222: 100%|██████████| 50/50 [00:01<00:00, 26.68it/s]\n",
      "epoch9 avg_loss:0.206: 100%|██████████| 50/50 [00:01<00:00, 28.12it/s]\n",
      "epoch10 avg_loss:0.187: 100%|██████████| 50/50 [00:01<00:00, 29.63it/s]\n",
      "100%|██████████| 943/943 [00:22<00:00, 42.35it/s]\n",
      "epoch11 avg_loss:0.175: 100%|██████████| 50/50 [00:02<00:00, 19.32it/s]\n",
      "epoch12 avg_loss:0.169: 100%|██████████| 50/50 [00:02<00:00, 21.09it/s]\n",
      "epoch13 avg_loss:0.160: 100%|██████████| 50/50 [00:02<00:00, 21.26it/s]\n",
      "epoch14 avg_loss:0.150: 100%|██████████| 50/50 [00:02<00:00, 24.38it/s]\n",
      "epoch15 avg_loss:0.146: 100%|██████████| 50/50 [00:02<00:00, 23.80it/s]\n",
      "100%|██████████| 943/943 [00:18<00:00, 50.99it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=50, n_epoch=15, valid_evaluator = evaluator, valid_per_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nDCG@3     MAP@3  Recall@3  epoch      loss\n",
       "0  0.404477  0.545157  0.111933      0       NaN\n",
       "0  0.398088  0.544185  0.112874      5  0.308484\n",
       "0  0.392882  0.537027  0.112438     10  0.186894\n",
       "0  0.393925  0.533581  0.112751     15  0.145944"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nDCG@3</th>\n      <th>MAP@3</th>\n      <th>Recall@3</th>\n      <th>epoch</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.404477</td>\n      <td>0.545157</td>\n      <td>0.111933</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.398088</td>\n      <td>0.544185</td>\n      <td>0.112874</td>\n      <td>5</td>\n      <td>0.308484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.392882</td>\n      <td>0.537027</td>\n      <td>0.112438</td>\n      <td>10</td>\n      <td>0.186894</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.393925</td>\n      <td>0.533581</td>\n      <td>0.112751</td>\n      <td>15</td>\n      <td>0.145944</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python386jvsc74a57bd01a6e8c4c71356cfd7f7f45384d81183fdca12e98ad893ee020bd76249bbd6be9",
   "display_name": "Python 3.8.6 64-bit ('pytorchcml-MJCCLiEQ-py3.8': poetry)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}