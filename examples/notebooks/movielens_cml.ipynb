{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyTorchCML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from PyTorchCML import losses, models, samplers, regularizers, evaluators, trainers\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download movielens dataset\n",
    "movielens = pd.read_csv(\n",
    "  'http://files.grouplens.org/datasets/movielens/ml-100k/u.data', \n",
    "    sep='\\t', header=None, index_col=None,\n",
    "    names = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "# Set user/item id and number of users/items.\n",
    "movielens.user_id -= 1\n",
    "movielens.item_id -= 1\n",
    "n_user = movielens.user_id.nunique()\n",
    "n_item = movielens.item_id.nunique()\n",
    "\n",
    "# make implicit feedback\n",
    "movielens.rating = (movielens.rating >= 4).astype(int)\n",
    "\n",
    "\n",
    "# train test split\n",
    "train, test = train_test_split(movielens)\n",
    "\n",
    "\n",
    "# all user item pairs\n",
    "df_all = pd.DataFrame(\n",
    "    [[u, i] for u,i in product(range(n_user), range(n_item))],\n",
    "    columns=[\"user_id\", \"item_id\"]\n",
    ")\n",
    "\n",
    "# frag train pairs\n",
    "df_all = pd.merge(\n",
    "    df_all, \n",
    "    train[[\"user_id\", \"item_id\", \"rating\"]], \n",
    "    on=[\"user_id\", \"item_id\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# remove train pairs\n",
    "test = pd.merge(\n",
    "    df_all[df_all.rating.isna()][[\"user_id\", \"item_id\"]], \n",
    "    test[[\"user_id\", \"item_id\", \"rating\"]], \n",
    "    on=[\"user_id\", \"item_id\"], \n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# numpy array\n",
    "train_set = train[train.rating == 1][[\"user_id\", \"item_id\"]].values\n",
    "test_set = test[[\"user_id\", \"item_id\", \"rating\"]].values\n",
    "\n",
    "# to torch.Tensor\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_set = torch.LongTensor(train_set).to(device)\n",
    "test_set = torch.LongTensor(test_set).to(device)\n"
   ]
  },
  {
   "source": [
    "## Defalt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_dim = 10\n",
    "model = models.CollaborativeMetricLearning(n_user, n_item, n_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = losses.SumTripletLoss(margin=1).to(device)\n",
    "sampler = samplers.BaseSampler(train_set, n_user, n_item, device=device, strict_negative=False)\n",
    "\n",
    "score_function_dict = {\n",
    "    \"nDCG\" : evaluators.ndcg,\n",
    "    \"MAP\" : evaluators.average_precision,\n",
    "    \"Recall\": evaluators.recall\n",
    "}\n",
    "evaluator = evaluators.UserwiseEvaluator(test_set, score_function_dict, ks=[3,5])\n",
    "trainer = trainers.BaseTrainer(model, optimizer, criterion, sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 943/943 [00:20<00:00, 46.66it/s]\n",
      "epoch1 avg_loss:0.931: 100%|██████████| 256/256 [00:06<00:00, 38.85it/s]\n",
      "epoch2 avg_loss:0.753: 100%|██████████| 256/256 [00:06<00:00, 40.74it/s]\n",
      "epoch3 avg_loss:0.658: 100%|██████████| 256/256 [00:06<00:00, 39.85it/s]\n",
      "epoch4 avg_loss:0.597: 100%|██████████| 256/256 [00:05<00:00, 46.31it/s]\n",
      "epoch5 avg_loss:0.558: 100%|██████████| 256/256 [00:07<00:00, 34.50it/s]\n",
      "epoch6 avg_loss:0.525: 100%|██████████| 256/256 [00:05<00:00, 44.82it/s]\n",
      "epoch7 avg_loss:0.500: 100%|██████████| 256/256 [00:06<00:00, 42.24it/s]\n",
      "epoch8 avg_loss:0.476: 100%|██████████| 256/256 [00:07<00:00, 35.35it/s]\n",
      "epoch9 avg_loss:0.455: 100%|██████████| 256/256 [00:07<00:00, 34.50it/s]\n",
      "epoch10 avg_loss:0.433: 100%|██████████| 256/256 [00:06<00:00, 41.74it/s]\n",
      "100%|██████████| 943/943 [00:21<00:00, 44.59it/s]\n",
      "epoch11 avg_loss:0.412: 100%|██████████| 256/256 [00:06<00:00, 41.59it/s]\n",
      "epoch12 avg_loss:0.387: 100%|██████████| 256/256 [00:06<00:00, 39.21it/s]\n",
      "epoch13 avg_loss:0.368: 100%|██████████| 256/256 [00:06<00:00, 42.29it/s]\n",
      "epoch14 avg_loss:0.350: 100%|██████████| 256/256 [00:06<00:00, 40.07it/s]\n",
      "epoch15 avg_loss:0.334: 100%|██████████| 256/256 [00:06<00:00, 42.41it/s]\n",
      "epoch16 avg_loss:0.319: 100%|██████████| 256/256 [00:06<00:00, 42.64it/s]\n",
      "epoch17 avg_loss:0.303: 100%|██████████| 256/256 [00:06<00:00, 41.52it/s]\n",
      "epoch18 avg_loss:0.294: 100%|██████████| 256/256 [00:06<00:00, 41.94it/s]\n",
      "epoch19 avg_loss:0.283: 100%|██████████| 256/256 [00:05<00:00, 44.28it/s]\n",
      "epoch20 avg_loss:0.274: 100%|██████████| 256/256 [00:06<00:00, 41.52it/s]\n",
      "100%|██████████| 943/943 [00:21<00:00, 43.05it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=256, n_epoch=20, valid_evaluator = evaluator, valid_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nDCG@3     MAP@3  Recall@3    nDCG@5     MAP@5  Recall@5  epoch      loss\n",
       "0  0.007423  0.012902  0.001568  0.008634  0.017922  0.002917      0       NaN\n",
       "0  0.042387  0.070078  0.006008  0.046897  0.084353  0.011537     10  0.432954\n",
       "0  0.202032  0.291888  0.044877  0.202131  0.311188  0.073077     20  0.274121"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nDCG@3</th>\n      <th>MAP@3</th>\n      <th>Recall@3</th>\n      <th>nDCG@5</th>\n      <th>MAP@5</th>\n      <th>Recall@5</th>\n      <th>epoch</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.007423</td>\n      <td>0.012902</td>\n      <td>0.001568</td>\n      <td>0.008634</td>\n      <td>0.017922</td>\n      <td>0.002917</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.042387</td>\n      <td>0.070078</td>\n      <td>0.006008</td>\n      <td>0.046897</td>\n      <td>0.084353</td>\n      <td>0.011537</td>\n      <td>10</td>\n      <td>0.432954</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.202032</td>\n      <td>0.291888</td>\n      <td>0.044877</td>\n      <td>0.202131</td>\n      <td>0.311188</td>\n      <td>0.073077</td>\n      <td>20</td>\n      <td>0.274121</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "source": [
    "## Strict Negative"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_dim = 10\n",
    "model = models.CollaborativeMetricLearning(n_user, n_item, n_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = losses.SumTripletLoss(margin=1).to(device)\n",
    "sampler = samplers.BaseSampler(train_set, n_user, n_item, device=device, strict_negative=True)\n",
    "\n",
    "score_function_dict = {\n",
    "    \"nDCG\" : evaluators.ndcg,\n",
    "    \"MAP\" : evaluators.average_precision,\n",
    "    \"Recall\": evaluators.recall\n",
    "}\n",
    "evaluator = evaluators.UserwiseEvaluator(test_set, score_function_dict, ks=[3,5])\n",
    "trainer = trainers.BaseTrainer(model, optimizer, criterion, sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 943/943 [00:18<00:00, 51.01it/s]\n",
      "epoch1 avg_loss:0.949: 100%|██████████| 256/256 [00:09<00:00, 26.99it/s]\n",
      "epoch2 avg_loss:0.792: 100%|██████████| 256/256 [00:09<00:00, 26.42it/s]\n",
      "epoch3 avg_loss:0.697: 100%|██████████| 256/256 [00:09<00:00, 25.81it/s]\n",
      "epoch4 avg_loss:0.636: 100%|██████████| 256/256 [00:09<00:00, 27.21it/s]\n",
      "epoch5 avg_loss:0.597: 100%|██████████| 256/256 [00:07<00:00, 34.30it/s]\n",
      "epoch6 avg_loss:0.564: 100%|██████████| 256/256 [00:07<00:00, 34.35it/s]\n",
      "epoch7 avg_loss:0.538: 100%|██████████| 256/256 [00:07<00:00, 34.95it/s]\n",
      "epoch8 avg_loss:0.517: 100%|██████████| 256/256 [00:08<00:00, 29.53it/s]\n",
      "epoch9 avg_loss:0.494: 100%|██████████| 256/256 [00:08<00:00, 28.63it/s]\n",
      "epoch10 avg_loss:0.471: 100%|██████████| 256/256 [00:07<00:00, 32.86it/s]\n",
      "100%|██████████| 943/943 [00:23<00:00, 40.65it/s]\n",
      "epoch11 avg_loss:0.450: 100%|██████████| 256/256 [00:07<00:00, 33.37it/s]\n",
      "epoch12 avg_loss:0.425: 100%|██████████| 256/256 [00:07<00:00, 33.03it/s]\n",
      "epoch13 avg_loss:0.405: 100%|██████████| 256/256 [00:09<00:00, 27.11it/s]\n",
      "epoch14 avg_loss:0.388: 100%|██████████| 256/256 [00:08<00:00, 29.81it/s]\n",
      "epoch15 avg_loss:0.369: 100%|██████████| 256/256 [00:07<00:00, 33.38it/s]\n",
      "epoch16 avg_loss:0.350: 100%|██████████| 256/256 [00:08<00:00, 29.23it/s]\n",
      "epoch17 avg_loss:0.333: 100%|██████████| 256/256 [00:08<00:00, 28.81it/s]\n",
      "epoch18 avg_loss:0.316: 100%|██████████| 256/256 [00:07<00:00, 33.58it/s]\n",
      "epoch19 avg_loss:0.301: 100%|██████████| 256/256 [00:07<00:00, 34.74it/s]\n",
      "epoch20 avg_loss:0.288: 100%|██████████| 256/256 [00:07<00:00, 33.92it/s]\n",
      "100%|██████████| 943/943 [00:24<00:00, 39.21it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=256, n_epoch=20, valid_evaluator = evaluator, valid_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nDCG@3     MAP@3  Recall@3    nDCG@5     MAP@5  Recall@5  epoch      loss\n",
       "0  0.020385  0.036939  0.001419  0.018477  0.041640  0.002321      0       NaN\n",
       "0  0.059936  0.091552  0.004546  0.068632  0.110379  0.009836     10  0.471340\n",
       "0  0.273629  0.369123  0.034714  0.272501  0.385817  0.059150     20  0.287908"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nDCG@3</th>\n      <th>MAP@3</th>\n      <th>Recall@3</th>\n      <th>nDCG@5</th>\n      <th>MAP@5</th>\n      <th>Recall@5</th>\n      <th>epoch</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.020385</td>\n      <td>0.036939</td>\n      <td>0.001419</td>\n      <td>0.018477</td>\n      <td>0.041640</td>\n      <td>0.002321</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.059936</td>\n      <td>0.091552</td>\n      <td>0.004546</td>\n      <td>0.068632</td>\n      <td>0.110379</td>\n      <td>0.009836</td>\n      <td>10</td>\n      <td>0.471340</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.273629</td>\n      <td>0.369123</td>\n      <td>0.034714</td>\n      <td>0.272501</td>\n      <td>0.385817</td>\n      <td>0.059150</td>\n      <td>20</td>\n      <td>0.287908</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "source": [
    "## Global Orthogonal Regularization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_dim = 10\n",
    "model = models.CollaborativeMetricLearning(n_user, n_item, n_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "regs = [regularizers.GlobalOrthogonalRegularizer(weight=1e-2)]\n",
    "criterion = losses.SumTripletLoss(margin=1, regularizers=regs).to(device)\n",
    "sampler = samplers.BaseSampler(train_set, n_user, n_item, device=device, strict_negative=True)\n",
    "\n",
    "score_function_dict = {\n",
    "    \"nDCG\" : evaluators.ndcg,\n",
    "    \"MAP\" : evaluators.average_precision,\n",
    "    \"Recall\": evaluators.recall\n",
    "}\n",
    "evaluator = evaluators.UserwiseEvaluator(test_set, score_function_dict, ks=[3,5])\n",
    "trainer = trainers.BaseTrainer(model, optimizer, criterion, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 943/943 [00:21<00:00, 44.39it/s]\n",
      "epoch1 avg_loss:0.948: 100%|██████████| 256/256 [00:11<00:00, 21.50it/s]\n",
      "epoch2 avg_loss:0.794: 100%|██████████| 256/256 [00:07<00:00, 32.35it/s]\n",
      "epoch3 avg_loss:0.700: 100%|██████████| 256/256 [00:07<00:00, 33.16it/s]\n",
      "epoch4 avg_loss:0.638: 100%|██████████| 256/256 [00:10<00:00, 23.36it/s]\n",
      "epoch5 avg_loss:0.598: 100%|██████████| 256/256 [00:07<00:00, 34.20it/s]\n",
      "epoch6 avg_loss:0.565: 100%|██████████| 256/256 [00:08<00:00, 31.81it/s]\n",
      "epoch7 avg_loss:0.540: 100%|██████████| 256/256 [00:07<00:00, 32.40it/s]\n",
      "epoch8 avg_loss:0.516: 100%|██████████| 256/256 [00:07<00:00, 33.46it/s]\n",
      "epoch9 avg_loss:0.493: 100%|██████████| 256/256 [00:13<00:00, 19.51it/s]\n",
      "epoch10 avg_loss:0.470: 100%|██████████| 256/256 [00:08<00:00, 31.15it/s]\n",
      "100%|██████████| 943/943 [00:24<00:00, 38.92it/s]\n",
      "epoch11 avg_loss:0.449: 100%|██████████| 256/256 [00:08<00:00, 28.90it/s]\n",
      "epoch12 avg_loss:0.422: 100%|██████████| 256/256 [00:08<00:00, 31.93it/s]\n",
      "epoch13 avg_loss:0.401: 100%|██████████| 256/256 [00:10<00:00, 23.42it/s]\n",
      "epoch14 avg_loss:0.377: 100%|██████████| 256/256 [00:08<00:00, 31.57it/s]\n",
      "epoch15 avg_loss:0.357: 100%|██████████| 256/256 [00:11<00:00, 22.92it/s]\n",
      "epoch16 avg_loss:0.338: 100%|██████████| 256/256 [00:07<00:00, 33.48it/s]\n",
      "epoch17 avg_loss:0.318: 100%|██████████| 256/256 [00:08<00:00, 30.68it/s]\n",
      "epoch18 avg_loss:0.304: 100%|██████████| 256/256 [00:08<00:00, 31.37it/s]\n",
      "epoch19 avg_loss:0.289: 100%|██████████| 256/256 [00:07<00:00, 33.49it/s]\n",
      "epoch20 avg_loss:0.281: 100%|██████████| 256/256 [00:13<00:00, 18.94it/s]\n",
      "100%|██████████| 943/943 [00:24<00:00, 38.13it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=256, n_epoch=20, valid_evaluator = evaluator, valid_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nDCG@3     MAP@3  Recall@3    nDCG@5     MAP@5  Recall@5  epoch      loss\n",
       "0  0.017032  0.029692  0.002178  0.017122  0.036462  0.003362      0       NaN\n",
       "0  0.074296  0.115500  0.005293  0.075128  0.125672  0.008741     10  0.469893\n",
       "0  0.276036  0.380877  0.035444  0.276884  0.395498  0.060833     20  0.281246"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nDCG@3</th>\n      <th>MAP@3</th>\n      <th>Recall@3</th>\n      <th>nDCG@5</th>\n      <th>MAP@5</th>\n      <th>Recall@5</th>\n      <th>epoch</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.017032</td>\n      <td>0.029692</td>\n      <td>0.002178</td>\n      <td>0.017122</td>\n      <td>0.036462</td>\n      <td>0.003362</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.074296</td>\n      <td>0.115500</td>\n      <td>0.005293</td>\n      <td>0.075128</td>\n      <td>0.125672</td>\n      <td>0.008741</td>\n      <td>10</td>\n      <td>0.469893</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.276036</td>\n      <td>0.380877</td>\n      <td>0.035444</td>\n      <td>0.276884</td>\n      <td>0.395498</td>\n      <td>0.060833</td>\n      <td>20</td>\n      <td>0.281246</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "source": [
    "## Two Stage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count = train.groupby(\"item_id\")[\"user_id\"].count()\n",
    "count_index = np.array(item_count.index)\n",
    "neg_weight = np.zeros(n_item)\n",
    "neg_weight[count_index] = item_count ** 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_dim = 10\n",
    "model = models.CollaborativeMetricLearning(n_user, n_item, n_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "regs = [regularizers.GlobalOrthogonalRegularizer(weight=1e-3)]\n",
    "criterion = losses.MinTripletLoss(margin=1, regularizers=regs).to(device)\n",
    "sampler = samplers.TwoStageSampler(\n",
    "    train_set, n_user, n_item, \n",
    "    neg_weight=neg_weight, n_neg_samples=5,\n",
    "    device=device, strict_negative=False\n",
    ")\n",
    "\n",
    "score_function_dict = {\n",
    "    \"nDCG\" : evaluators.ndcg,\n",
    "    \"MAP\" : evaluators.average_precision,\n",
    "    \"Recall\": evaluators.recall\n",
    "}\n",
    "evaluator = evaluators.UserwiseEvaluator(test_set, score_function_dict, ks=[3,5])\n",
    "trainer = trainers.BaseTrainer(model, optimizer, criterion, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 943/943 [00:27<00:00, 34.76it/s]\n",
      "epoch1 avg_loss:1.495: 100%|██████████| 256/256 [00:08<00:00, 31.49it/s]\n",
      "epoch2 avg_loss:1.321: 100%|██████████| 256/256 [00:07<00:00, 36.29it/s]\n",
      "epoch3 avg_loss:1.207: 100%|██████████| 256/256 [00:06<00:00, 37.32it/s]\n",
      "epoch4 avg_loss:1.144: 100%|██████████| 256/256 [00:16<00:00, 15.77it/s]\n",
      "epoch5 avg_loss:1.108: 100%|██████████| 256/256 [00:11<00:00, 22.04it/s]\n",
      "epoch6 avg_loss:1.084: 100%|██████████| 256/256 [00:12<00:00, 20.87it/s]\n",
      "epoch7 avg_loss:1.074: 100%|██████████| 256/256 [00:08<00:00, 28.55it/s]\n",
      "epoch8 avg_loss:1.060: 100%|██████████| 256/256 [00:06<00:00, 38.29it/s]\n",
      "epoch9 avg_loss:1.050: 100%|██████████| 256/256 [00:06<00:00, 37.60it/s]\n",
      "epoch10 avg_loss:1.044: 100%|██████████| 256/256 [00:05<00:00, 43.88it/s]\n",
      "100%|██████████| 943/943 [00:22<00:00, 42.64it/s]\n",
      "epoch11 avg_loss:1.036: 100%|██████████| 256/256 [00:06<00:00, 40.12it/s]\n",
      "epoch12 avg_loss:1.030: 100%|██████████| 256/256 [00:06<00:00, 39.84it/s]\n",
      "epoch13 avg_loss:1.028: 100%|██████████| 256/256 [00:08<00:00, 30.95it/s]\n",
      "epoch14 avg_loss:1.024: 100%|██████████| 256/256 [00:06<00:00, 41.29it/s]\n",
      "epoch15 avg_loss:1.020: 100%|██████████| 256/256 [00:06<00:00, 36.79it/s]\n",
      "epoch16 avg_loss:1.018: 100%|██████████| 256/256 [00:06<00:00, 38.61it/s]\n",
      "epoch17 avg_loss:1.014: 100%|██████████| 256/256 [00:06<00:00, 38.05it/s]\n",
      "epoch18 avg_loss:1.011: 100%|██████████| 256/256 [00:08<00:00, 30.10it/s]\n",
      "epoch19 avg_loss:1.008: 100%|██████████| 256/256 [00:06<00:00, 39.79it/s]\n",
      "epoch20 avg_loss:1.001: 100%|██████████| 256/256 [00:06<00:00, 39.21it/s]\n",
      "100%|██████████| 943/943 [00:22<00:00, 41.77it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=256, n_epoch=20, valid_evaluator = evaluator, valid_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nDCG@3     MAP@3  Recall@3    nDCG@5     MAP@5  Recall@5  epoch      loss\n",
       "0  0.012986  0.022004  0.001167  0.013278  0.028190  0.002582      0       NaN\n",
       "0  0.207166  0.293655  0.019897  0.200064  0.305768  0.033076     10  1.043901\n",
       "0  0.356546  0.484093  0.052573  0.326033  0.484409  0.074481     20  1.001474"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nDCG@3</th>\n      <th>MAP@3</th>\n      <th>Recall@3</th>\n      <th>nDCG@5</th>\n      <th>MAP@5</th>\n      <th>Recall@5</th>\n      <th>epoch</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.012986</td>\n      <td>0.022004</td>\n      <td>0.001167</td>\n      <td>0.013278</td>\n      <td>0.028190</td>\n      <td>0.002582</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.207166</td>\n      <td>0.293655</td>\n      <td>0.019897</td>\n      <td>0.200064</td>\n      <td>0.305768</td>\n      <td>0.033076</td>\n      <td>10</td>\n      <td>1.043901</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.356546</td>\n      <td>0.484093</td>\n      <td>0.052573</td>\n      <td>0.326033</td>\n      <td>0.484409</td>\n      <td>0.074481</td>\n      <td>20</td>\n      <td>1.001474</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "source": [
    "## model weighted negative sampler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_init(X, dim):\n",
    "    \"\"\"\n",
    "    Args :\n",
    "        X : csr_matrix which element is 0 or 1.\n",
    "        dim : number of dimention\n",
    "    \"\"\"\n",
    "    svd = TruncatedSVD(n_components=10)\n",
    "    U_ = svd.fit_transform(X)\n",
    "    V_ = svd.components_\n",
    "\n",
    "    s = (U_.sum(axis=1).mean() + V_.sum(axis=0).mean()) / 2\n",
    "    U = 2 ** 0.5 * U_ - (1 / n_dim) ** 0.5 * s * np.ones_like(U_)\n",
    "    V = 2 ** 0.5 * V_ + (1 / n_dim) ** 0.5 / s * np.ones_like(V_)\n",
    "    ub = -(2 / n_dim) ** 0.5 * U_.sum(axis=1) / s\n",
    "    vb = (2 / n_dim) ** 0.5 * V_.sum(axis=0) * s\n",
    "\n",
    "    return U, V, ub, vb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 10\n",
    "X = csr_matrix(\n",
    "    (np.ones(train_set.shape[0]), (train_set[:,0], train_set[:,1])),\n",
    "    shape=[n_user, n_item]\n",
    ")\n",
    "U, V, ub, vb = svd_init(X, n_dim)\n",
    "neg_weight_model = models.LogitMatrixFactorization(\n",
    "    n_user, n_item, n_dim, max_norm=None,\n",
    "    user_embedding_init = torch.Tensor(U), \n",
    "    item_embedding_init = torch.Tensor(V.T),\n",
    "    user_bias_init = torch.Tensor(ub), \n",
    "    item_bias_init = torch.Tensor(vb)\n",
    ").to(device)\n",
    "neg_weight_model.link_weight = lambda x : 1 - torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "model = models.CollaborativeMetricLearning(n_user, n_item, n_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = losses.SumTripletLoss(margin=1).to(device)\n",
    "sampler = samplers.BaseSampler(\n",
    "    train_set, n_user, n_item, \n",
    "    neg_weight=neg_weight_model,\n",
    "    device=device, strict_negative=False\n",
    ")\n",
    "\n",
    "score_function_dict = {\n",
    "    \"nDCG\" : evaluators.ndcg,\n",
    "    \"MAP\" : evaluators.average_precision,\n",
    "    \"Recall\": evaluators.recall\n",
    "}\n",
    "evaluator = evaluators.UserwiseEvaluator(test_set, score_function_dict, ks=[3,5])\n",
    "trainer = trainers.BaseTrainer(model, optimizer, criterion, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 943/943 [00:16<00:00, 55.70it/s]\n",
      "epoch1 avg_loss:0.968: 100%|██████████| 256/256 [00:05<00:00, 44.73it/s]\n",
      "epoch2 avg_loss:0.846: 100%|██████████| 256/256 [00:05<00:00, 44.17it/s]\n",
      "epoch3 avg_loss:0.766: 100%|██████████| 256/256 [00:06<00:00, 36.72it/s]\n",
      "epoch4 avg_loss:0.718: 100%|██████████| 256/256 [00:06<00:00, 38.69it/s]\n",
      "epoch5 avg_loss:0.677: 100%|██████████| 256/256 [00:07<00:00, 34.02it/s]\n",
      "epoch6 avg_loss:0.650: 100%|██████████| 256/256 [00:06<00:00, 41.09it/s]\n",
      "epoch7 avg_loss:0.629: 100%|██████████| 256/256 [00:05<00:00, 46.11it/s]\n",
      "epoch8 avg_loss:0.610: 100%|██████████| 256/256 [00:05<00:00, 45.69it/s]\n",
      "epoch9 avg_loss:0.589: 100%|██████████| 256/256 [00:07<00:00, 34.75it/s]\n",
      "epoch10 avg_loss:0.572: 100%|██████████| 256/256 [00:07<00:00, 33.05it/s]\n",
      "100%|██████████| 943/943 [00:19<00:00, 47.84it/s]\n",
      "epoch11 avg_loss:0.555: 100%|██████████| 256/256 [00:07<00:00, 33.20it/s]\n",
      "epoch12 avg_loss:0.539: 100%|██████████| 256/256 [00:06<00:00, 39.77it/s]\n",
      "epoch13 avg_loss:0.521: 100%|██████████| 256/256 [00:06<00:00, 40.92it/s]\n",
      "epoch14 avg_loss:0.507: 100%|██████████| 256/256 [00:06<00:00, 41.77it/s]\n",
      "epoch15 avg_loss:0.489: 100%|██████████| 256/256 [00:06<00:00, 41.66it/s]\n",
      "epoch16 avg_loss:0.479: 100%|██████████| 256/256 [00:06<00:00, 40.17it/s]\n",
      "epoch17 avg_loss:0.466: 100%|██████████| 256/256 [00:05<00:00, 43.27it/s]\n",
      "epoch18 avg_loss:0.452: 100%|██████████| 256/256 [00:06<00:00, 38.08it/s]\n",
      "epoch19 avg_loss:0.440: 100%|██████████| 256/256 [00:07<00:00, 36.39it/s]\n",
      "epoch20 avg_loss:0.430: 100%|██████████| 256/256 [00:06<00:00, 38.09it/s]\n",
      "100%|██████████| 943/943 [00:20<00:00, 45.11it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_batch=256, n_epoch=20, valid_evaluator = evaluator, valid_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     nDCG@3     MAP@3  Recall@3   nDCG@5     MAP@5  Recall@5  epoch      loss\n",
       "0  0.016209  0.030399  0.001955  0.01690  0.038264  0.003477      0       NaN\n",
       "0  0.051292  0.078208  0.004285  0.05536  0.094836  0.007510     10  0.572125\n",
       "0  0.233268  0.322552  0.030232  0.23401  0.336276  0.049536     20  0.430135"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nDCG@3</th>\n      <th>MAP@3</th>\n      <th>Recall@3</th>\n      <th>nDCG@5</th>\n      <th>MAP@5</th>\n      <th>Recall@5</th>\n      <th>epoch</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.016209</td>\n      <td>0.030399</td>\n      <td>0.001955</td>\n      <td>0.01690</td>\n      <td>0.038264</td>\n      <td>0.003477</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.051292</td>\n      <td>0.078208</td>\n      <td>0.004285</td>\n      <td>0.05536</td>\n      <td>0.094836</td>\n      <td>0.007510</td>\n      <td>10</td>\n      <td>0.572125</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.233268</td>\n      <td>0.322552</td>\n      <td>0.030232</td>\n      <td>0.23401</td>\n      <td>0.336276</td>\n      <td>0.049536</td>\n      <td>20</td>\n      <td>0.430135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('pytorchcml-MJCCLiEQ-py3.8': poetry)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "interpreter": {
   "hash": "1a6e8c4c71356cfd7f7f45384d81183fdca12e98ad893ee020bd76249bbd6be9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}